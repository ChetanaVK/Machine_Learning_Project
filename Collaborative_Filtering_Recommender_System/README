Collaborative Filtering Recommender System 

Dataset: 
a. Training Dataset File Description: 
The file big220.txt is the dataset being used. 6
The first line of each file contains the movie id followed by a colon.  Each subsequent 
line in the file corresponds to a rating from a customer and its date in the following 
format:

CustomerID,Rating,Date

- Ratings are on a five-star (integral) scale from 1 to 5. 
- Dates have the format YYYY-MM-DD.

b.   Movies File Description
Movie information in "movie_titles.txt" is in the following format: 

MovieID,YearOfRelease,Title

- MovieID do not correspond to actual Netflix movie ids or IMDB movie ids. 
- YearOfRelease can range from 1890 to 2005.
- Title is the Netflix movie title and may not correspond to titles used on other sites.  
Titles are in English.

c.    Text file "probe.txt".  It consists of lines indicating a movie id, followed by a colon, and 
then customer ID.

MovieID1: 
CustomerID11 
CustomerID12

d.   The program predicts the all ratings the customers gave the movies.

Example of an output:

if the input is:

111:
3245
5666
6789
225:
1234
3456

then the prediction file looks like:

111:
3.0
3.4
4.0
225:
1.0
2.07

which means that customer 3245 would have rated movie 111 3.0 stars, that customer 
5666 would have rated it slightly higher at 3.4 stars etc.,

Implementation:
1. Specify Hyper Parameters
2. Load the dataset
3. Clean Data
4. Reduce the number of datapoints by removing movies with too less reviews and 
users who give too less reviews.
5. Convert the DataFrame with just 3 columns into a large matrix with all unique 
movies on the rows and unique users on the column and the associated ratings in 
the matrix cell; also return another boolean DataFrame, R, of same size as df that 
contains, in ith row and jth column, information about whether ith movie was rated 
by jth user.
6. Read the movie titles from the provided file and put them in a DataFrame.
7. Randomly initialize parameters X and Theta.
8. Normalize Y.
9. Compute the cost as sum of all the squared errors to be used in fmin_cg.
10. Compute gradients and then flatten the parameters to use with fmin_cg.
11. Computes cost and the gradients to be used in our gradient descent algorithm.
12. Compute Gradient Descent to find minimum cost, return the final X and Theta to be 
used in our algorithm.
13. Calculate the Root Mean Squared Error.
14. Plot the cost and rmse against multiple epochs.
15. Flatten X and Theta to be used in fmincg.
16. Unroll parameters to retrieve X and Theta.
17. Perform User rating Predictions.
18. Calculate RMSE for the probe dataset.
