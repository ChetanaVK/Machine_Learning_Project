{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#import libraries\nimport pandas as pd\nimport numpy as np\nimport math\nimport re\nfrom scipy.sparse import csr_matrix\nimport scipy.optimize\nimport matplotlib\nmatplotlib.use('Agg')\nimport seaborn as sns\nsns.set_style(\"darkgrid\")","metadata":{"_uuid":"5444d49c-50d0-4668-b270-683e9f04fbdb","_cell_guid":"845993a1-7766-42b2-90e2-d26cecac3f64","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-08T00:19:04.659200Z","iopub.execute_input":"2022-06-08T00:19:04.659712Z","iopub.status.idle":"2022-06-08T00:19:05.311234Z","shell.execute_reply.started":"2022-06-08T00:19:04.659581Z","shell.execute_reply":"2022-06-08T00:19:05.310251Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"#Specifying Hyper Parameters \nuser = 0\nnumFeatures = 1000\nlambd = 1.5\nalpha = 0.0025\nepoch = 50\nprobe_filename = \"probe.txt\"\nmaxIterFmin = 50\n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loadData():\n    '''\n    load the dataset into a pandas DataFrame with 2 colums \"Cust_Id\" and \"Rating\" and return it\n    '''\n    \n    #loading 'big220.txt' that only contains ratings for the first 220 movies,\n    \n    #print(\"loading big220.txt\")\n    df1 = pd.read_csv('input-ds/big220.txt', header = None, names = ['Cust_Id', 'Rating'], usecols = [0,1])\n    \n    df1['Rating'] = df1['Rating'].astype(float)\n    \n    df = df1\n    \n    df.index = np.arange(0,len(df))\n    print('Full dataset shape: {}'.format(df.shape))\n    return df\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cleanData(df):\n    \n    #add a new column \"Movie_Id\" to the DataFrame that associates each rating to a movie\n    \n    df_nan_values = pd.DataFrame(pd.isnull(df.Rating))\n    df_nan_values = df_nan_values[df_nan_values['Rating'] == True]\n    df_nan_values = df_nan_values.reset_index()\n\n    np_movie = []\n    movie_id = 1\n\n    for i,j in zip(df_nan_values['index'][1:],df_nan_values['index'][:-1]):\n        temp = np.full((1,i-j-1), movie_id)\n        np_movie = np.append(np_movie, temp)\n        movie_id += 1\n\n    # Account for last record and corresponding length\n    last_record = np.full((1,len(df) - df_nan_values.iloc[-1, 0] - 1),movie_id)\n    np_movie = np.append(np_movie, last_record)\n\n    # remove those Movie ID rows\n    df = df[pd.notnull(df['Rating'])]\n\n    df['Movie_Id'] = np_movie.astype(int)\n    df['Cust_Id'] = df['Cust_Id'].astype(int)\n    \n    print(\"finished cleaning data\")\n    return df\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def spliceData(df):\n    #reduces the number of datapoints by removing movies with too less reviews and \n    #users who give too less reviews\n    \n    f = ['count','mean']\n\n    summary_movie_df = df.groupby('Movie_Id')['Rating'].agg(f)\n    summary_movie_df.index = summary_movie_df.index.map(int)\n    \n    movie_benchmark = round(summary_movie_df['count'].quantile(0.8),0)\n    drop_movie_list = summary_movie_df[summary_movie_df['count'] < movie_benchmark].index\n\n    #print('Movie minimum times of review: {}'.format(movie_benchmark))\n\n    df_cust_summary = df.groupby('Cust_Id')['Rating'].agg(f)\n    df_cust_summary.index = df_cust_summary.index.map(int)\n    \n    cust_benchmark = round(df_cust_summary['count'].quantile(0.8),0)\n    drop_cust_list = df_cust_summary[df_cust_summary['count'] < cust_benchmark].index\n\n    #print('Customer minimum times of review: {}'.format(cust_benchmark))\n    \n    #print('Original Shape: {}'.format(df.shape))\n    df = df[~df['Movie_Id'].isin(drop_movie_list)]\n    df = df[~df['Cust_Id'].isin(drop_cust_list)]\n    #print('After Trim Shape: {}'.format(df.shape))\n    \n    return df\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pivotData(df):\n    #convert the DataFrame with just 3 columns into a large matrix with all unique movies on the rows \n    #and unique users on the column and the associated ratings in the matrix cell;\n    #also return another boolean DataFrame, R, of same size as df that contains, in ith row and jth column,\n    #information about whether ith movie was rated by jth user\n    \n    f = ['count','mean']\n\n    #print(\"pivoting the matrix\")\n    Y = pd.pivot_table(df,values='Rating',index='Movie_Id',columns='Cust_Id')\n    #print(\"finished pivoting the matrix\")\n    \n    R = (Y > 0)*1\n    #print(\"R shape:\",R.shape)\n    #print(\"Y shape:\",Y.shape)\n    return Y, R","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def readMovies(filename):\n    #read the movie titles from the provided file and puts them in a DataFrame\n    \n    title_df = pd.read_csv('movie_titles.csv', encoding = \"ISO-8859-1\", header = None, names = ['Movie_Id', 'Year', 'Name'])\n    title_df.set_index('Movie_Id', inplace = True)\n    title_df = title_df.as_matrix()\n    return title_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def randInit(numCustomers, numMovies, numFeatures):\n    #randomly initialize parameters X and Theta \n    \n    X = pd.DataFrame(np.random.uniform(-0.1,0.1,size=(numMovies, numFeatures)))\n    #print(\"X shape:\", X.shape)\n    Theta = pd.DataFrame(np.random.uniform(-0.1,0.1,size=(numCustomers, numFeatures)))\n    #print(\"Theta shape\", Theta.shape)\n    return (Theta,X)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize(Y):\n    #mean normalize Y\n    \n    movies, cust = Y.shape\n    mu = Y.mean(axis = 1)\n    Y = Y.sub(mu, axis=0)\n    return Y, mu\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fminCostFunc(params, Y, R, numCustomers, numMovies, numFeatures, lamd):\n    #compute the cost as sum of all the squared errors to be used in fmin_cg\n    \n    X, Theta = reshapeParams(params, numMovies, numCustomers, numFeatures)\n    \n    transTheta = Theta.transpose()    \n    yHat = X.dot(transTheta)\n    \n    yHat = np.multiply(yHat,R)\n    \n    cost = 0.5*(np.nansum(np.square(yHat-Y)))\n    cost += (lambd/2.0)*(np.nansum(np.square(Theta)))\n    cost += (lambd/2.0)*(np.nansum(np.square(X)))\n    \n    return cost","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fminGradient(params, Y, R, numCustomers, numMovies, numFeatures, lamd):\n    #compute gradients and then flatten the parameters to use with fmin_cg \n    \n    X, Theta = reshapeParams(params, numMovies, numCustomers, numFeatures)\n    transTheta = Theta.transpose()    \n    yHat = X.dot(transTheta)\n    yHat = np.multiply(yHat,R)\n    yHat -= Y\n    X_grad = yHat.dot(Theta) + lambd*X\n    Theta_grad = yHat.transpose().dot(X) + lambd*Theta\n\n    return flattenParams(X_grad, Theta_grad)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ourCostFunc(Y,Theta,X,lambd,R):\n    #computes cost and the gradients to be uesd in our gradient descent algorithm   \n\n    \n    transTheta = Theta.transpose()    \n    yHat = X.dot(transTheta)\n\n    \n    yHat = np.multiply(yHat,R)\n    \n    cost = 0.5*(np.sum(np.square(yHat-Y)))\n    cost += (lambd/2.0)*(np.sum(np.square(Theta)))\n    cost += (lambd/2.0)*(np.sum(np.square(X)))\n    \n    yHat -= Y\n    \n    X_grad = yHat.dot(Theta) + lambd*X\n    Theta_grad = yHat.transpose().dot(X) + lambd*Theta\n    \n    return cost, X_grad, Theta_grad\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ourGradDesc(Y, Theta, X, lambd,alpha, epoch, R):\n    #compute Gradient Descent to find minimum cost, \n    #return the final X and Theta to be used in our algorithm\n    \n    costList = []\n    rmseList = []\n    \n    for i in range(epoch):\n        cost, X_grad, Theta_grad = ourCostFunc(Y, Theta, X, lambd, R)\n        ourRMSE = rmse(Y, Theta, X, R)\n        X -= alpha*(X_grad)\n        Theta -= alpha*(Theta_grad)\n        #print()\n        #print(\"epoch\",i+1)\n        #print(\"cost:\", cost)\n        #print(\"RMSE:\", ourRMSE)\n        costList.append(cost)\n        rmseList.append(ourRMSE)\n        \n    plotGraph(costList, rmseList)\n    return X, Theta\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rmse(Y, Theta, X, R):    \n    #calculate the Root Mean Squared Error \n  \n    transTheta = Theta.transpose()\n    yHat = X.dot(transTheta) \n    yHat = np.multiply(yHat,R)\n    yHat -= Y\n    squaredError = np.square(yHat)\n    mse = np.sum(squaredError)/np.sum(R)\n    rmse = np.sqrt(mse)\n    return rmse\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plotGraph(costList, rmseList):\n    #plot the cost and rmse against multiple epoches\n\n    matplotlib.pyplot.plot(range(len(costList)),costList, \"r-\")    \n    matplotlib.pyplot.xlabel(\"Iterations\")  \n    matplotlib.pyplot.ylabel(\"Cost (J)\") \n    matplotlib.pyplot.savefig(\"cost.png\")\n    matplotlib.pyplot.close()\n    \n    matplotlib.pyplot.plot(range(len(rmseList)), rmseList, \"b-\")\n    matplotlib.pyplot.xlabel(\"Iterations\")  \n    matplotlib.pyplot.ylabel(\"RMSE\")\n    matplotlib.pyplot.savefig(\"rmse.png\")\n    matplotlib.pyplot.close()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def flattenParams(X, Theta):\n    '''\n    flatten X and Theta to be used in fmincg\n    '''\n    return np.concatenate((X.flatten(),Theta.flatten()))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def reshapeParams(flattened_XandTheta, mynm, mynu, mynf):\n    #unroll parameters to retrieve X and Theta\n    \n    reX = flattened_XandTheta[:int(mynm*mynf)].reshape((mynm,mynf))\n    reTheta = flattened_XandTheta[int(mynm*mynf):].reshape((mynu,mynf))\n    \n    return reX, reTheta","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def recommend(user, prediction_matrix, mu, movies,R):\n    #recommend top 10 movies for the user\n    \n    predictions_user = prediction_matrix[:,user] + mu.flatten()\n    userR = R[:,user]\n    \n    #inverting R to only consider non-rated movies for recommendation\n    userR = -1*userR + 1\n    \n    predictions_user = np.multiply(predictions_user, userR)\n    # Sort user predictions from highest to lowest\n    pred_idxs_sorted = np.argsort(predictions_user)\n    pred_idxs_sorted[:] = pred_idxs_sorted[::-1]\n\n    print(\"Top recommendations for you:\")\n    for i in range(10):\n        print('Predicting rating %0.1f for movie %s.' % \n        (predictions_user[pred_idxs_sorted[i]],(movies[pred_idxs_sorted[i]][1])))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def probe(probe_filename, finalYHat, movieIds, userIds, Y):\n    #calculate RMSE for the probe dataset\n    \n    se = 0\n    count = 0\n    userDict = dict(zip(userIds,range(len(userIds))))\n    movieDict = dict(zip(movieIds, range(len(movieIds))))\n    skipMovie = False\n    with open(probe_filename, \"r\") as file:\n        file = file.readlines()\n        for line in file:\n            line = line.strip()\n            if \":\" in line:\n                skipMovie = False\n                currMovie = int(line[:-1])\n                if currMovie not in movieDict:\n                    skipMovie = True\n                else:\n                    row = movieDict[currMovie]\n                    #print(\"movie:\", currMovie)\n            else:\n                if (not skipMovie):\n                    currUser = int(line)\n                    if currUser in userDict:\n                        col = userDict[currUser]\n                        se += (Y[row, col] - finalYHat[row, col])**2\n                        count += 1\n        mse = se/count\n        rmse = np.sqrt(mse)\n    return rmse","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ourMain():\n    '''\n    main function to drive our algorithm\n    '''\n    \n    print(\"loading dataset...\")\n    df = loadData()\n    print(\"done\")\n    \n    print(\"cleaning dataset...\")\n    cleanDf = cleanData(df)\n    print(\"done\")\n    \n    print(\"splicing dataset...\")\n    splicedDf = spliceData(cleanDf)\n    print(\"done\")\n    \n    print(\"pivoting dataset...\")\n    Y, R = pivotData(splicedDf)\n    print(\"done\")\n    \n    print(\"reading movies...\")\n    movies = readMovies(\"movie_titles.csv\")\n    numMovies, numCustomers = Y.shape\n    print(\"done\")\n    \n    print(\"randomly initializing Theta and X...\")\n    Theta,X = randInit(numCustomers, numMovies, numFeatures)\n    print(\"done\")\n    \n    print(\"normalizing Y...\")\n    Y, mu = normalize(Y)\n    print(\"done\")\n    \n    movieIds = Y.index\n    userIds = Y.columns.values\n    Y = Y.as_matrix()\n    Theta = Theta.as_matrix()\n    R = R.as_matrix()\n    X = X.as_matrix()\n    mu = mu.as_matrix()\n    \n    Y[np.isnan(Y)] = 0    \n    \n    print(\"running gradient descent...\")\n    X, Theta = ourGradDesc(Y, Theta, X, lambd,alpha,epoch,R)\n    print(\"done\")\n    \n    finalYHat = X.dot(Theta.transpose())\n    \n    print(\"recommending user...\")\n    recommend(user, finalYHat, mu, movies,R)\n    print(\"done\")\n    \n    print(\"calculating RMSE on the probe dataset...\")\n    probeRMSE = probe(probe_filename, finalYHat, movieIds, userIds, Y)\n    print(\"done\")\n    print(\"RMSE for probe dataset:\",probeRMSE)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fminMain():\n    '''\n    main function to drive fmin_cg algorithm\n    '''\n    print(\"loading dataset...\")\n    df = loadData()\n    print(\"done\")\n    \n    print(\"cleaning dataset...\")\n    cleanDf = cleanData(df)\n    print(\"done\")\n    \n    print(\"splicing dataset...\")\n    splicedDf = spliceData(cleanDf)\n    print(\"done\")\n    \n    print(\"pivoting dataset...\")\n    Y, R = pivotData(splicedDf)\n    print(\"done\")\n    \n    print(\"reading movies...\")\n    movies = readMovies(\"movie_titles.csv\")\n    numMovies, numCustomers = Y.shape\n    print(\"done\")\n    \n    print(\"randomly initializing Theta and X...\")\n    Theta,X = randInit(numCustomers, numMovies, numFeatures)\n    print(\"done\")\n    \n    print(\"normalizing Y...\")\n    Y, mu = normalize(Y)\n    print(\"done\")\n    \n    movieIds = Y.index\n    userIds = Y.columns.values\n    Y = Y.as_matrix()\n    Theta = Theta.as_matrix()\n    R = R.as_matrix()\n    X = X.as_matrix()\n    mu = mu.as_matrix()\n    \n    Y[np.isnan(Y)] = 0    \n        \n    flatParams = flattenParams(X,Theta)\n    \n    print(\"running advanced optimization algorithm...\")\n    result = scipy.optimize.fmin_cg(fminCostFunc, x0=flatParams, fprime=fminGradient, \n                               args=(Y,R,numCustomers,numMovies,numFeatures,lambd), \n                                maxiter=maxIterFmin,disp=True,full_output=True)\n    print(\"done\")\n    \n    print(result)\n    X, Theta = reshapeParams(result[0], numMovies, numCustomers, numFeatures)\n    RMSE = rmse(Y, Theta, X, R)\n    print(\"RMSE:\",RMSE)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    #ourMain()\n    fminMain()","metadata":{},"execution_count":null,"outputs":[]}]}